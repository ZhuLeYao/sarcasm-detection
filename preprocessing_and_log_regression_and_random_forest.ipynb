{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7CcICR9DSNA",
        "outputId": "2ad2e531-a5a0-4fb0-c0b1-d1e975a48805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_to_file = '/content/drive/My Drive/Colab Notebooks/train-balanced-sarcasm.csv'\n",
        "data_train = pd.read_csv(path_to_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkwxYRp7DcsT",
        "outputId": "c4183669-4b94-4ce0-8bc4-258009274d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_to_file = '/content/drive/My Drive/Colab Notebooks/test-balanced-final.csv'\n",
        "data_train = pd.read_csv(path_to_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezPn3Q2nDkCV"
      },
      "source": [
        "DARYL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "Tuu7o1FZGY7J",
        "outputId": "c7c7f059-b0a6-444e-d983-c6ab68f724ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2022.9.24)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 8.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234927 sha256=dd4a2f65dbf591d1195946998c8222415cc8e48e180c26e34b7749cd04b27dd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/e3/f2/1de1c2e3ed742e1df73e0f15d58864e50c7e64f607b548d6cf\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.2.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Duplicate rows in the dataset: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2d2ddee3-651c-4b05-8870-2b5ef17a2608\", \"filename.csv\", 71946452)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install vaderSentiment\n",
        "!pip install emoji\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "import emoji\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "\n",
        "### removing duplicate rows\n",
        "\n",
        "data_train.drop_duplicates(keep='first',inplace=True)\n",
        "data_train.drop_duplicates(keep='first',inplace=True)\n",
        "print('Number of Duplicate rows in the dataset:',len(data_train[data_train.duplicated() == True]))\n",
        "\n",
        "\n",
        "## score calculated as number of upvotes - downvotes\n",
        "data_train['score'] = data_train['ups'] - data_train['downs']\n",
        "\n",
        "def compute_basic_features(text1,text2):\n",
        "    ###computes basic features between child and parent comment\n",
        "       ### 1. child_len: length of the child comment\n",
        "       ### 2. parent_len: length of the parent comment\n",
        "       ### 3. distance_cp: distance between both the child and parent statement.More the distance more the constrast in\n",
        "       ### sentiments. \n",
        "    text1=text1.tolist()\n",
        "    text2=text2.tolist()\n",
        "    sent_id = SentimentIntensityAnalyzer()\n",
        "    child_len=[]\n",
        "    parent_len=[]\n",
        "    distance_cp=[]\n",
        "    for com1,com2 in zip(text1,text2):\n",
        "        token1 = com1.split()\n",
        "        token2 = com2.split()\n",
        "        # length of the  child\n",
        "        child_length = len(token1)\n",
        "        child_len.append(child_length)\n",
        "        # length of the  parent\n",
        "        parent_length = len(token2)\n",
        "        parent_len.append(parent_length)\n",
        "        score1 =  sent_id.polarity_scores(com1)['compound']\n",
        "        score2 =  sent_id.polarity_scores(com2)['compound']\n",
        "        distance = abs(score1-score2)\n",
        "        distance_cp.append(distance)\n",
        "    return child_len,parent_len,distance_cp\n",
        "        \n",
        "    \n",
        "data_train['comment']=data_train['comment'].fillna(\"\")\n",
        "data_train['parent_comment']=data_train['parent_comment'].fillna(\"\")\n",
        "\n",
        "new_basic=compute_basic_features(data_train['comment'],data_train['parent_comment'])\n",
        "#creating child_len, parent_len and distance_cp features\n",
        "data_train['child_len']=new_basic[0]\n",
        "data_train['parent_len']=new_basic[1]\n",
        "data_train['distance_cp']=new_basic[2]\n",
        "\n",
        "\n",
        "sent_id=SentimentIntensityAnalyzer()\n",
        "exclude = set(string.punctuation)\n",
        "def compute_advanced_features(text):\n",
        "    '''Function will compute all the 11 features for every sentence passed as input'''\n",
        "    tokens = text.split()\n",
        "    ## noun_verb_c\n",
        "    noun=['NN', 'NNS', 'NNP', 'NNPS']\n",
        "    verb=['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
        "    stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "    intensifier_list = ['absolutely','amazingly','astoundingly','at all','awful','bitterly','bloody','completely','crazy','dead','dreadfully',\\\n",
        "                    'colossally','especially','exceptionally','excessively','extremely','extraordinarily','fantastically','frightfully','fully',\\\n",
        "                    'hella','incredibly','insanely','literally','mad','mightily','outrageously',\\\n",
        "                    'particularly','phenomenally','precious','quite','radically','rather','real','really','remarkably','ridiculously',\\\n",
        "                    'so','somewhat','strikingly','super','supremely','terribly','terrifically','too','totally','unbelievably','veritable','very']\n",
        "    emoji_list=[\"\\U0001f600\",\"\\U0001f603\",\"\\U0001f604\",\"\\U0001f601\",\"\\U0001f606\",\"\\U0001f605\",\"\\U0001f923\",\"\\U0001f602\",\"\\U0001f642\",\"\\U0001f643\"\n",
        "                \"\\U0001f609\",\"\\U0001f60A\",\"\\U0001f607\",\"\\U0001f61b\",\"\\U0001f61c\",\"\\U0001f92a\",\"\\U0001f61d\",\"\\U0001f911\"]\n",
        "    interjection_list= ['hey','hurray','wow','brr','shh','oops','bravo','what','argh','oh dear','ouch','umm','phew','yoo-hoo','oh my','oh no',\\\n",
        "                        'eww','boo','snap','jeez','hey','yipee','orgh','bah','duh','congrats','yay','whoa','alas','hey','oh','eh','ah','zoinks',\\\n",
        "                        'hush','ahem','well','ahem','yum','bingo']\n",
        "\n",
        "    ## initialize cs\n",
        "    noun_count,verb_count = 0,0\n",
        "    neg_int_c,pos_int_c = 0,0\n",
        "    emoji_c,punctuation_c=0,0\n",
        "    interjection_c,uppercase_c,repeated_letters_c=0,0,0\n",
        "    flip_c,pos_c,neg_c=0,0,0\n",
        "    previous_word_score={'pos':1,'neg':0}\n",
        "    for word in tokens:\n",
        "        if word not in stopwords:\n",
        "            ### feature 1 :noun_verb_c\n",
        "            tag = nltk.pos_tag(word_tokenize(word))[0][1]\n",
        "            if tag in noun:\n",
        "                noun_count+=1\n",
        "            elif tag in verb:\n",
        "                verb_count+=1\n",
        "                \n",
        "            ### feature2,3 neg_int_c,pos_int_c\n",
        "            \n",
        "            score = sent_id.polarity_scores(word)\n",
        "            if word in intensifier_list:\n",
        "                if score['neg']:\n",
        "                    neg_int_c+=1\n",
        "                elif score['pos']:\n",
        "                    pos_int_c+=1\n",
        "            ### feature 4 : emoji c \n",
        "            if word in emoji_list:\n",
        "                emoji_c+=1   \n",
        "            ### feature5 interjection_c\n",
        "            if word in interjection_list:\n",
        "                interjection_c+=1 \n",
        "                \n",
        "            ### feature6,7  : uppercase,repeated_letters\n",
        "            if word == word.upper():\n",
        "                uppercase_c+=1\n",
        "                \n",
        "            find_ = [(x.start(),x.end()) for x in re.finditer(r'(\\w)\\1\\1', word)]\n",
        "            \n",
        "            if find_:\n",
        "                repeated_letters_c+=1\n",
        "            ## feature 8 : punctuation c \n",
        "            punctuation = set(string.punctuation)\n",
        "            for i in  list(word):\n",
        "                #print(i)\n",
        "                if i in punctuation:\n",
        "                    punctuation_c+=1\n",
        "                    \n",
        "            ## feature 9,10,11 - flip c ,pos c and neg c\n",
        "            \n",
        "            word_exclude_punc = ''.join(ch for ch in word if ch not in exclude)  \n",
        "            score_new = sent_id.polarity_scores(word_exclude_punc)\n",
        "\n",
        "            if score_new['pos']:\n",
        "                pos_c+=1\n",
        "                if previous_word_score['neg']:\n",
        "                    flip_c+=1\n",
        "\n",
        "            if score_new['neg']:\n",
        "                neg_c+=1\n",
        "                if previous_word_score['pos']:\n",
        "                    flip_c+=1\n",
        "            previous_word_score = score_new\n",
        "            \n",
        "    sum_nv = noun_count + verb_count\n",
        "    return sum_nv,neg_int_c,pos_int_c,emoji_c,interjection_c,uppercase_c,repeated_letters_c,punctuation_c,flip_c,pos_c,neg_c\n",
        "\n",
        "def mutating_df(dataframe):\n",
        "    commentlist=dataframe['comment'].tolist()\n",
        "    sum_nvl=[]\n",
        "    neg_int_cl=[]\n",
        "    pos_int_cl=[]\n",
        "    emoji_cl=[]\n",
        "    interjection_cl=[]\n",
        "    uppercase_cl=[]\n",
        "    repeated_letters_cl=[]\n",
        "    punctuation_cl=[]\n",
        "    flip_cl=[]\n",
        "    pos_cl=[]\n",
        "    neg_cl=[]\n",
        "    for comment in commentlist:\n",
        "        result=compute_advanced_features(comment)\n",
        "        sum_nvl.append(result[0])\n",
        "        neg_int_cl.append(result[1])\n",
        "        pos_int_cl.append(result[2])\n",
        "        emoji_cl.append(result[3])\n",
        "        interjection_cl.append(result[4])\n",
        "        uppercase_cl.append(result[5])\n",
        "        repeated_letters_cl.append(result[6])\n",
        "        punctuation_cl.append(result[7])\n",
        "        flip_cl.append(result[8])\n",
        "        pos_cl.append(result[9])\n",
        "        neg_cl.append(result[10])\n",
        "    data_train['sum_nv']=sum_nvl\n",
        "    data_train['neg_int_c']=neg_int_cl\n",
        "    data_train['pos_int_c']=pos_int_cl\n",
        "    data_train['emoji_c']=emoji_cl\n",
        "    data_train['interjection_c']=interjection_cl\n",
        "    data_train['uppercase_c']=uppercase_cl\n",
        "    data_train['repeated_letters_c']=repeated_letters_cl\n",
        "    data_train['punctuation_c']=punctuation_cl\n",
        "    data_train['flip_c']=flip_cl\n",
        "    data_train['pos_c']=pos_cl\n",
        "    data_train['neg_c']=neg_cl\n",
        "    return dataframe\n",
        "\n",
        "mutating_df(data_train)\n",
        "\n",
        "from google.colab import files\n",
        "data_train.to_csv('filename.csv') \n",
        "files.download('filename.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQmdP8WOj8aT",
        "outputId": "af5a8355-4183-4323-ebcd-288e801fe980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_to_file = '/content/drive/My Drive/Colab Notebooks/filename.csv'\n",
        "data_train = pd.read_csv(path_to_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOM4v6ZXHc-0"
      },
      "source": [
        "LE YAO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7D2RmFYRKbpc",
        "outputId": "510f999b-9301-4ec9-d4ff-72ac2c0bb7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         0.375\n",
            "1        -0.125\n",
            "2         0.375\n",
            "3         0.000\n",
            "4        -0.250\n",
            "          ...  \n",
            "251585   -0.500\n",
            "251586    0.000\n",
            "251587    0.750\n",
            "251588    0.000\n",
            "251589    0.375\n",
            "Name: senti_score, Length: 251590, dtype: float64\n",
            "<bound method NDFrame.head of         Unnamed: 0  label                                            comment  \\\n",
            "0                0      0  Actually most of her supporters and sane peopl...   \n",
            "1                1      0  They can't survive without an echo chamber whi...   \n",
            "2                2      0             you're pretty cute yourself 1729 total   \n",
            "3                3      0        If you kill me you'll crash the meme market   \n",
            "4                4      0  I bet he wrote that last message as he was sob...   \n",
            "...            ...    ...                                                ...   \n",
            "251585      251603      1               Respect your elders you little snot.   \n",
            "251586      251604      1  I'm just glad they won't be using taxpayer mon...   \n",
            "251587      251605      1                what.. with this awesome narration?   \n",
            "251588      251606      1                              He looks trustworthy.   \n",
            "251589      251607      1               Well yeah, but it'll work this time.   \n",
            "\n",
            "                      author      subreddit  score  ups  downs     date  \\\n",
            "0                Quinnjester       politics      3    3      0  2016-09   \n",
            "1       TheGettysburgAddress     The_Donald      0   -1     -1  2016-11   \n",
            "2         Sempiternally_free      2007scape      0   -1     -1  2016-11   \n",
            "3                 Catacomb82      AskReddit      0   -1     -1  2016-10   \n",
            "4           Dorian-throwaway       niceguys      0   -1     -1  2016-11   \n",
            "...                      ...            ...    ...  ...    ...      ...   \n",
            "251585        Tiffany_Butler         sports      7    7      0  2009-06   \n",
            "251586        harryballsagna         canada      8    8      0  2009-06   \n",
            "251587               aberant           lost      4    4      0  2009-04   \n",
            "251588          permaculture  unitedkingdom      1    1      0  2009-01   \n",
            "251589          SovereignMan       politics      1    1      0  2009-02   \n",
            "\n",
            "        Unnamed: 8  ... uppercase_c  repeated_letters_c  punctuation_c  \\\n",
            "0       1473569605  ...           1                   0              5   \n",
            "1       1478788413  ...           0                   0              2   \n",
            "2       1478042903  ...           1                   0              0   \n",
            "3       1477412597  ...           0                   0              0   \n",
            "4       1477962278  ...           1                   0              1   \n",
            "...            ...  ...         ...                 ...            ...   \n",
            "251585  1245445833  ...           0                   0              1   \n",
            "251586  1246140814  ...           0                   0              3   \n",
            "251587  1240452084  ...           0                   0              3   \n",
            "251588  1231343418  ...           0                   0              1   \n",
            "251589  1235780770  ...           0                   0              3   \n",
            "\n",
            "        flip_c  pos_c  neg_c  \\\n",
            "0            0      1      0   \n",
            "1            0      1      0   \n",
            "2            0      2      0   \n",
            "3            0      0      2   \n",
            "4            0      0      1   \n",
            "...        ...    ...    ...   \n",
            "251585       0      1      0   \n",
            "251586       0      1      1   \n",
            "251587       0      1      0   \n",
            "251588       0      1      0   \n",
            "251589       0      2      0   \n",
            "\n",
            "                                comment_without_stopwords  \\\n",
            "0       Actually supporters sane people saw Media doin...   \n",
            "1       They can't survive without echo chamber great ...   \n",
            "2                                 pretty cute 1729 total    \n",
            "3                              If kill crash meme market    \n",
            "4                       I bet wrote last message sobbing    \n",
            "...                                                   ...   \n",
            "251585                        Respect elders little snot    \n",
            "251586  I'm glad using taxpayer money investigate made...   \n",
            "251587                                 awesome narration    \n",
            "251588                              He looks trustworthy    \n",
            "251589                         Well yeah it'll work time    \n",
            "\n",
            "                                      After_lemmatization  \\\n",
            "0       Actually supporter sane people saw Media doing...   \n",
            "1       They n't survive without echo chamber great Am...   \n",
            "2                                      pretty cute total    \n",
            "3                                 kill crash meme market    \n",
            "4                         bet wrote last message sobbing    \n",
            "...                                                   ...   \n",
            "251585                         Respect elder little snot    \n",
            "251586  glad using taxpayer money investigate made pos...   \n",
            "251587                                 awesome narration    \n",
            "251588                                  look trustworthy    \n",
            "251589                           Well yeah 'll work time    \n",
            "\n",
            "                                                 pos_tags  senti_score  \n",
            "0       [(Actually, RB), (supporter, JJ), (sane, NN), ...        0.375  \n",
            "1       [(They, PRP), (n't, RB), (survive, VBD), (with...       -0.125  \n",
            "2                 [(pretty, RB), (cute, JJ), (total, NN)]        0.375  \n",
            "3       [(kill, VB), (crash, JJ), (meme, NN), (market,...        0.000  \n",
            "4       [(bet, RB), (wrote, VBD), (last, JJ), (message...       -0.250  \n",
            "...                                                   ...          ...  \n",
            "251585  [(Respect, JJ), (elder, NN), (little, JJ), (sn...       -0.500  \n",
            "251586  [(glad, NN), (using, VBG), (taxpayer, JJ), (mo...        0.000  \n",
            "251587                   [(awesome, JJ), (narration, NN)]        0.750  \n",
            "251588                    [(look, NN), (trustworthy, NN)]        0.000  \n",
            "251589  [(Well, RB), (yeah, RB), ('ll, MD), (work, VB)...        0.375  \n",
            "\n",
            "[251590 rows x 29 columns]>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_540f34dd-9064-4a8b-b97d-a2980d91abf4\", \"trainly1.csv\", 132121236)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import spacy\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from IPython.display import clear_output\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import plotly\n",
        "import nltk\n",
        "import ssl\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "string.punctuation\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('sentiwordnet')\n",
        "plotly.offline.init_notebook_mode (connected = True)\n",
        "\n",
        "Edited_Comments = data_train['comment'].copy()\n",
        "data_train['comment_without_stopwords'] = Edited_Comments\n",
        "data_train['comment_without_stopwords'].replace('', np.nan, inplace=True)\n",
        "data_train.dropna(subset=['comment_without_stopwords'], inplace=True)\n",
        "data_train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "def make_sentences(data,name):\n",
        "    data[name]=data[name].apply(lambda x:' '.join([i+' ' for i in x]))\n",
        "    # Removing double spaces if created\n",
        "    data[name]=data[name].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n",
        "\n",
        "\n",
        "def remove_stopwords_tokenize(data,name):\n",
        "      \n",
        "    def myTokenizer(txt):\n",
        "        pattern = '(?<=\\w)[^\\w\\s]*(?!\\w)'\n",
        "        txt = re.sub(pattern, '', txt)\n",
        "        txt = TweetTokenizer().tokenize(txt)\n",
        "        return txt\n",
        "\n",
        "    def getting(sen):\n",
        "        example_sent = sen\n",
        "        \n",
        "        filtered_sentence = [] \n",
        "\n",
        "        stop_words = set(stopwords.words('english')) \n",
        "\n",
        "        word_tokens = myTokenizer(example_sent)\n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
        "        \n",
        "        return filtered_sentence\n",
        "    # Using \"getting(sen)\" function to append edited sentence to data\n",
        "    x=[]\n",
        "    for i in data[name].values:\n",
        "        x.append(getting(i))\n",
        "    data[name]=x\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def Lemmatization(data,name):\n",
        "    def getting2(sen):\n",
        "        \n",
        "        example = sen\n",
        "        output_sentence =[]\n",
        "        word_tokens2 = word_tokenize(example)\n",
        "        lemmatized_output = [lemmatizer.lemmatize(w) for w in word_tokens2]\n",
        "        \n",
        "        # Remove characters which have length less than 2  \n",
        "        without_single_chr = [word for word in lemmatized_output if len(word) > 2]\n",
        "        # Remove numbers\n",
        "        cleaned_data_title = [word for word in without_single_chr if not word.isnumeric()]\n",
        "        \n",
        "        return cleaned_data_title\n",
        "    # Using \"getting2(sen)\" function to append edited sentence to data\n",
        "    x=[]\n",
        "    for i in data[name].values:\n",
        "        x.append(getting2(i))\n",
        "    data[name]=x\n",
        "\n",
        "# Using tokenizer and removing the stopwords\n",
        "remove_stopwords_tokenize(data_train,'comment_without_stopwords')\n",
        "# Converting all the texts back to sentences\n",
        "make_sentences(data_train,'comment_without_stopwords')\n",
        "\n",
        "#Edits After Lemmatization\n",
        "final_Edit = data_train['comment_without_stopwords'].copy()\n",
        "data_train[\"After_lemmatization\"] = final_Edit\n",
        "\n",
        "# Using the Lemmatization function to lemmatize the hotel data\n",
        "Lemmatization(data_train,'After_lemmatization')\n",
        "# Converting all the texts back to sentences\n",
        "make_sentences(data_train,'After_lemmatization')\n",
        "\n",
        "data_train.head(6)\n",
        "\n",
        "pos=neg=obj=count=0\n",
        "\n",
        "postagging = []\n",
        "\n",
        "for review in data_train['After_lemmatization']:\n",
        "    list = word_tokenize(review)\n",
        "    postagging.append(nltk.pos_tag(list))\n",
        "\n",
        "data_train['pos_tags'] = postagging\n",
        "\n",
        "def penn_to_wn(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    elif tag.startswith('V'):\n",
        "        return wn.VERB\n",
        "    return None\n",
        "\n",
        "\n",
        "# Returns list of pos-neg and objective score. But returns empty list if not present in senti wordnet.\n",
        "def get_sentiment(word,tag):\n",
        "    wn_tag = penn_to_wn(tag)\n",
        "    \n",
        "    if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
        "        return []\n",
        "\n",
        "    #Lemmatization\n",
        "    lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "    if not lemma:\n",
        "        return []\n",
        "\n",
        "    #Synset is a special kind of a simple interface that is present in NLTK to look up words in WordNet. \n",
        "    #Synset instances are the groupings of synonymous words that express the same concept. \n",
        "    #Some of the words have only one Synset and some have several.\n",
        "    synsets = wn.synsets(word, pos=wn_tag)\n",
        "    if not synsets:\n",
        "        return []\n",
        "\n",
        "    # Take the first sense, the most common\n",
        "    synset = synsets[0]\n",
        "    swn_synset = swn.senti_synset(synset.name())\n",
        "\n",
        "    return [synset.name(), swn_synset.pos_score(),swn_synset.neg_score(),swn_synset.obj_score()]\n",
        "\n",
        "    pos=neg=obj=count=0\n",
        "    \n",
        "    ###################################################################################\n",
        "senti_score = []\n",
        "\n",
        "for pos_val in data_train['pos_tags']:\n",
        "    senti_val = [get_sentiment(x,y) for (x,y) in pos_val]\n",
        "    for score in senti_val:\n",
        "        try:\n",
        "            pos = pos + score[1]  #positive score is stored at 2nd position\n",
        "            neg = neg + score[2]  #negative score is stored at 3rd position\n",
        "        except:\n",
        "            continue\n",
        "    senti_score.append(pos - neg)\n",
        "    pos=neg=0    \n",
        "    \n",
        "data_train['senti_score'] = senti_score\n",
        "print(data_train['senti_score'])\n",
        "\n",
        "print(data_train.head)\n",
        "\n",
        "overall=[]\n",
        "for i in range(len(data_train)):\n",
        "    if data_train['senti_score'][i]>= 0.05:\n",
        "        overall.append('Positive')\n",
        "    elif data_train['senti_score'][i]<= -0.05:\n",
        "        overall.append('Negative')\n",
        "    else:\n",
        "        overall.append('Neutral')\n",
        "data_train['Overall Sentiment']=overall\n",
        "data_train.head(10)\n",
        "\n",
        "data_train['comment_new'] = data_train['After_lemmatization'].copy()\n",
        "\n",
        "from google.colab import files\n",
        "data_train.to_csv('trainly1.csv') \n",
        "files.download('trainly1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_to_file = '/content/drive/My Drive/Colab Notebooks/trainly1.csv'\n",
        "data_train = pd.read_csv(path_to_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI2Da9sUDakP",
        "outputId": "457c22c8-75b7-4df6-d3fc-fe33b0af9191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIGNSLYCDKR_"
      },
      "outputs": [],
      "source": [
        "# The following code creates a word-document matrix.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vec = CountVectorizer()\n",
        "X = vec.fit_transform(data_train['comment_new'].values.astype('U'))\n",
        "df = pd.DataFrame(X.toarray(), columns = vec.get_feature_names())\n",
        "df.head(3)\n",
        "\n",
        "vect = CountVectorizer()\n",
        "vect.fit(data_train['reviews_text_new'])\n",
        "vect.get_feature_names()\n",
        "# transform training data into a 'document-term matrix'\n",
        "simple_train_dtm = vect.transform(data_train['reviews_text_new'])\n",
        "print(simple_train_dtm)\n",
        "\n",
        "### Creating a python object of the class CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_counts = CountVectorizer(tokenizer= word_tokenize, # type of tokenization\n",
        "                             ngram_range=(1,3)) # number of n-grams\n",
        "\n",
        "bow_data = bow_counts.fit_transform(data_train['reviews_text_new'])\n",
        "\n",
        "from google.colab import files\n",
        "data_train.to_csv('trainly2.csv') \n",
        "files.download('trainly2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SI JING"
      ],
      "metadata": {
        "id": "ZcuGwTf8VeOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_comments = data_train['comment'].copy()\n",
        "data_train['comments tfidf'] = tfidf_comments\n",
        "data_train[\"comments tfidf\"] = data_train[\"comments tfidf\"].astype(str)\n",
        "def create_tfidf_ngram_vectorizer(text_train, ngram_range = (1,1), **kwargs):\n",
        "    vectorizer = TfidfVectorizer(ngram_range = ngram_range, **kwargs)\n",
        "    vectorizer.fit(text_train)\n",
        "    return vectorizer\n",
        "\n",
        "for i in range(1,3):\n",
        "    tfidf_igram_vectorizer = create_tfidf_ngram_vectorizer(data_train['comments tfidf'], ngram_range = (1,i))\n",
        "    X_train_transformed = tfidf_igram_vectorizer.transform(data_train['comments tfidf'])\n",
        "    \n",
        "    base_classifier = sklearnClassifier(SGDClassifier(), X_train_transformed, y_train)\n",
        "\n",
        "from google.colab import files\n",
        "data_train.to_csv('trainsijing.csv') \n",
        "files.download('trainsijing.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "u708Y_HZ70-n",
        "outputId": "2e8476d1-7964-4ea0-d588-765746a2778d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3b120ef4dbfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfidf_comments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comments tfidf'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_comments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment tfidf\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment tfidf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_tfidf_ngram_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDeDaLaRHY62"
      },
      "source": [
        "EN EN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1vS3pxeJfzj"
      },
      "source": [
        "LOG REGRESSION AND RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_to_file = '/content/drive/My Drive/Colab Notebooks/trainly1.csv'\n",
        "data_train = pd.read_csv(path_to_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo4nNA7w77pb",
        "outputId": "8d648f97-29f3-479f-de70-f93e70fe5772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_to_file = '/content/drive/My Drive/Colab Notebooks/filename1.csv'\n",
        "data_test = pd.read_csv(path_to_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NqxXva6zu-z",
        "outputId": "db5d2c1f-7160-4a60-970d-e108ad9c4c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_to_file = '/content/drive/My Drive/Colab Notebooks/trainbalancedfinal6k.csv'\n",
        "data_train = pd.read_csv(path_to_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfAXM2zZ8hCu",
        "outputId": "77e66418-eea2-406a-bf6d-9c686a020086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_to_file = '/content/drive/My Drive/Colab Notebooks/testbalancedfinal2k.csv'\n",
        "data_test = pd.read_csv(path_to_file)"
      ],
      "metadata": {
        "id": "GKl64pMIzwgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "#split train and target class\n",
        "y_train = data_train['label']\n",
        "x_train = data_train.drop(['comment', 'author','subreddit', 'date', 'created_utc', 'parent_comment', 'comment_without_stopwords', 'After_lemmatization', \n",
        "                           'pos_tags', 'comment_new', 'Overall Sentiment', 'label', 'Index'], axis=1)\n",
        "#logregression\n",
        "param = {'C': [10**-2,10**-1,10**0,10**1,10**2]}\n",
        "#test unbalanced\n",
        "y_test = data_test['label']\n",
        "x_test = data_test.drop(['comment', 'author','subreddit', 'date', 'parent_comment', 'comment_without_stopwords', 'After_lemmatization', \n",
        "                           'pos_tags', 'comment_new', 'Overall Sentiment', 'code', 'label', 'Index'], axis=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O95WDN_Zhu99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "scaler = StandardScaler()\n",
        "x_trainstd = scaler.fit_transform(x_train)\n",
        "lrm=LogisticRegression()\n",
        "rfm = RandomForestClassifier(n_estimators = 140, random_state = 42)\n",
        "#cvv for logistic regression\n",
        "scores = cross_val_score(lrm, x_trainstd, y_train, cv=5)\n",
        "print(scores)\n",
        "#cvv for random forest classifier\n",
        "scores= cross_val_score(rfm,x_trainstd,y_train,cv=5)\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "JmMi7Ir51-4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b97dcd44-4e06-4bf8-8420-c1daf762d021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.514735   0.5557     0.55112    0.54989    0.50485252]\n",
            "[0.501435   0.354745   0.345695   0.39764    0.49859749]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "scaler = StandardScaler()\n",
        "x_trainstd = scaler.fit_transform(x_train)\n",
        "lrm=LogisticRegression()\n",
        "rfm = RandomForestClassifier(n_estimators = 140, random_state = 42)\n",
        "#cvv for logistic regression\n",
        "scores = cross_val_score(lrm, x_trainstd, y_train, cv=5, scoring='f1_macro')\n",
        "print(scores)\n",
        "#cvv for random forest classifier\n",
        "scores= cross_val_score(rfm,x_trainstd,y_train,cv=5, scoring='f1_macro')\n",
        "print(scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_9Tz3C8x-r3",
        "outputId": "c8047c60-ce75-4c77-f246-5c58e1c95251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.37003529 0.54392352 0.54979942 0.53180456 0.35767138]\n",
            "[0.3339705  0.35458173 0.34569443 0.39744952 0.33276254]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "scaler = StandardScaler()\n",
        "x_trainstd = scaler.fit_transform(x_train)\n",
        "lrm=LogisticRegression()\n",
        "rfm = RandomForestClassifier(n_estimators = 140, random_state = 42)\n",
        "#cvv for logistic regression\n",
        "scores = cross_val_score(lrm, x_trainstd, y_train, cv=5, scoring='f1_weighted')\n",
        "print(scores)\n",
        "#cvv for random forest classifier\n",
        "scores= cross_val_score(rfm,x_trainstd,y_train,cv=5, scoring='f1_weighted')\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KPw4KRjyAXi",
        "outputId": "91fa72a1-1b51-4daf-acab-aefabb994734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.37090181 0.54413386 0.54972945 0.53154139 0.35679047]\n",
            "[0.334929   0.35461119 0.34569267 0.39741888 0.33180951]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##before redundancy\n",
        "lr_model_all = LogisticRegression() # Logistic regression\n",
        "lr_model_all.fit(x_train, y_train) # Fitting a logistic regression model\n",
        "\n",
        "## Predicting the output\n",
        "test_pred_lr_all = lr_model_all.predict(x_test) # Class prediction\n",
        "\n",
        "#confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, test_pred_lr_all).ravel()\n",
        "print((tn, fp, fn, tp))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "# Print a classification report\n",
        "print(classification_report(y_test,test_pred_lr_all))\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "print(log_loss(y_test, test_pred_lr_all))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8-94y0lEfNg",
        "outputId": "73c5e69b-801a-4fcc-a32d-4b4fbb03845f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 125798, 0, 125791)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00    125799\n",
            "           1       0.50      1.00      0.67    125791\n",
            "\n",
            "    accuracy                           0.50    251590\n",
            "   macro avg       0.75      0.50      0.33    251590\n",
            "weighted avg       0.75      0.50      0.33    251590\n",
            "\n",
            "17.270199851681294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest\n",
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestClassifier(n_estimators = 140, random_state = 42, verbose = 2)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(x_train, y_train)\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(x_test)\n",
        "\n",
        "#confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(predictions, y_test).ravel()\n",
        "print((tn, fp, fn, tp))\n",
        "#classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "id": "QOizK_WFM3nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY_aB9TjJHFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa87291-a2b5-4bc9-f198-1a488b21c1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(103426, 22373, 92591, 33200)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.82      0.64    125799\n",
            "           1       0.60      0.26      0.37    125791\n",
            "\n",
            "    accuracy                           0.54    251590\n",
            "   macro avg       0.56      0.54      0.50    251590\n",
            "weighted avg       0.56      0.54      0.50    251590\n",
            "\n",
            "15.782558046257074\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "x_trainstd = scaler.fit_transform(x_train)\n",
        "x_teststd = scaler.transform(x_test)\n",
        "##before redundancy\n",
        "lr_model_all = LogisticRegression() # Logistic regression\n",
        "lr_model_all.fit(x_trainstd, y_train) # Fitting a logistic regression model\n",
        "\n",
        "## Predicting the output\n",
        "test_pred_lr_all = lr_model_all.predict(x_teststd) # Class prediction\n",
        "\n",
        "#confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, test_pred_lr_all).ravel()\n",
        "print((tn, fp, fn, tp))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "# Print a classification report\n",
        "print(classification_report(y_test,test_pred_lr_all))\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "print(log_loss(y_test, test_pred_lr_all))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "x_trainstd = scaler.fit_transform(x_train)\n",
        "x_teststd = scaler.transform(x_test)\n",
        "\n",
        "#random forest\n",
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestClassifier(n_estimators = 140, random_state = 42, verbose = 2)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(x_trainstd, y_train)\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(x_teststd)\n",
        "\n",
        "#confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(predictions, y_test).ravel()\n",
        "print((tn, fp, fn, tp))\n",
        "#classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "id": "PXY9l2DcQ94z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "scaler = Normalizer()\n",
        "x_trainnorm = scaler.fit_transform(x_train)\n",
        "x_testnorm = scaler.transform(x_test)\n",
        "##before redundancy\n",
        "lr_model_all = LogisticRegression() # Logistic regression\n",
        "lr_model_all.fit(x_trainnorm, y_train) # Fitting a logistic regression model\n",
        "\n",
        "## Predicting the output\n",
        "test_pred_lr_all = lr_model_all.predict(x_testnorm) # Class prediction\n",
        "\n",
        "#confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, test_pred_lr_all).ravel()\n",
        "print((tn, fp, fn, tp))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "# Print a classification report\n",
        "print(classification_report(y_test,test_pred_lr_all))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuvFLqHckSn6",
        "outputId": "9812772d-1f39-4866-82f0-fb632e129b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(125798, 1, 125791, 0)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67    125799\n",
            "           1       0.00      0.00      0.00    125791\n",
            "\n",
            "    accuracy                           0.50    251590\n",
            "   macro avg       0.25      0.50      0.33    251590\n",
            "weighted avg       0.25      0.50      0.33    251590\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "scaler = Normalizer()\n",
        "x_trainnorm = scaler.fit_transform(x_train)\n",
        "x_testnorm = scaler.transform(x_test)\n",
        "\n",
        "#random forest\n",
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestClassifier(n_estimators = 140, random_state = 42, verbose = 2)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(x_trainnorm, y_train)\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(x_testnorm)\n",
        "\n",
        "#confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(predictions, y_test).ravel()\n",
        "print((tn, fp, fn, tp))\n",
        "#classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "id": "RixkwKdhWgfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "x_trainrs = scaler.fit_transform(x_train)\n",
        "x_testrs = scaler.transform(x_test)\n",
        "##before redundancy\n",
        "lr_model_all = LogisticRegression(max_iter = 500) # Logistic regression\n",
        "lr_model_all.fit(x_trainrs, y_train) # Fitting a logistic regression model\n",
        "\n",
        "## Predicting the output\n",
        "test_pred_lr_all = lr_model_all.predict(x_testrs) # Class prediction\n",
        "\n",
        "#confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, test_pred_lr_all).ravel()\n",
        "print((tn, fp, fn, tp))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "# Print a classification report\n",
        "print(classification_report(y_test,test_pred_lr_all))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfCgeOeqkTQL",
        "outputId": "89653557-e4eb-453b-a355-4cef464d69b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(103374, 22425, 92532, 33259)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.82      0.64    125799\n",
            "           1       0.60      0.26      0.37    125791\n",
            "\n",
            "    accuracy                           0.54    251590\n",
            "   macro avg       0.56      0.54      0.50    251590\n",
            "weighted avg       0.56      0.54      0.50    251590\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "x_trainrs = scaler.fit_transform(x_train)\n",
        "x_testrs = scaler.transform(x_test)\n",
        "\n",
        "#random forest\n",
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestClassifier(n_estimators = 140, random_state = 42, verbose = 2)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(x_trainrs, y_train)\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(x_testrs)\n",
        "\n",
        "#confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(predictions, y_test).ravel()\n",
        "print((tn, fp, fn, tp))\n",
        "#classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "id": "5Ane7jLdlPaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "x_trainmm = scaler.fit_transform(x_train)\n",
        "x_testmm = scaler.transform(x_test)\n",
        "##before redundancy\n",
        "lr_model_all = LogisticRegression(max_iter=500) # Logistic regression\n",
        "lr_model_all.fit(x_trainmm, y_train) # Fitting a logistic regression model\n",
        "\n",
        "## Predicting the output\n",
        "test_pred_lr_all = lr_model_all.predict(x_testmm) # Class prediction\n",
        "\n",
        "#confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, test_pred_lr_all).ravel()\n",
        "print((tn, fp, fn, tp))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "# Print a classification report\n",
        "print(classification_report(y_test,test_pred_lr_all))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keUmHrAYiSIe",
        "outputId": "5a6c6750-f404-4572-a08f-e6ef921dd59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(110090, 15709, 102609, 23182)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.88      0.65    125799\n",
            "           1       0.60      0.18      0.28    125791\n",
            "\n",
            "    accuracy                           0.53    251590\n",
            "   macro avg       0.56      0.53      0.47    251590\n",
            "weighted avg       0.56      0.53      0.47    251590\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "x_trainmm = scaler.fit_transform(x_train)\n",
        "x_testmm = scaler.transform(x_test)\n",
        "\n",
        "#random forest\n",
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestClassifier(n_estimators = 140, random_state = 42, verbose = 2)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(x_trainmm, y_train)\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(x_testmm)\n",
        "\n",
        "#confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(predictions, y_test).ravel()\n",
        "print((tn, fp, fn, tp))\n",
        "#classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "id": "yy3JUMovwOEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn import feature_selection\n",
        "scaler = StandardScaler()\n",
        "x_trainstd = scaler.fit_transform(x_train)\n",
        "x_teststd = scaler.transform(x_test)\n",
        "\n",
        "lr_model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "\n",
        "gs_model = GridSearchCV(estimator=lr_model, param_grid=param, pre_dispatch=None)\n",
        "gs_model.fit(x_trainstd, y_train)\n",
        "\n",
        "# Train a LR model with best parameters\n",
        "model = LogisticRegression(**gs_model.best_params_, penalty='l1', solver='liblinear')\n",
        "model.fit(x_trainstd, y_train)\n",
        "\n",
        "coef = model.coef_[0]\n",
        "imp_features = pd.Series(x_train.columns)[list(coef!=0)]\n",
        "X_train = x_train[imp_features]\n",
        "X_test = x_test[imp_features]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "##after redundancy\n",
        "lr_model_all1 = LogisticRegression() # Logistic regression\n",
        "lr_model_all1.fit(X_train, y_train) # Fitting a logistic regression model\n",
        "\n",
        "## Predicting the output\n",
        "test_pred_lr_all = lr_model_all1.predict(X_test) # Class prediction\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "# Print a classification report\n",
        "print(classification_report(y_test,test_pred_lr_all))\n"
      ],
      "metadata": {
        "id": "MLouTqAql6DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest\n",
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestClassifier(n_estimators = 140, random_state = 42, verbose = 2)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_trainstd = scaler.fit_transform(x_train)\n",
        "x_teststd = scaler.transform(x_test)\n",
        "# Train the model on training data\n",
        "rf.fit(x_trainstd, y_train)\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(x_teststd)\n",
        "\n",
        "#confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(predictions, y_test).ravel()\n",
        "print((tn, fp, fn, tp))\n",
        "#classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "id": "IUDZHuAjA96x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}